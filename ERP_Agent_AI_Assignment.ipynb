{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2JMBZfvQO_y"
      },
      "source": [
        "# Assignment AI Agent for Money Requests\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Welcome to the **AI Agent for Money Requests**, a cutting-edge application designed to streamline your project funding requests. This app leverages advanced AI technologies, including:\n",
        "\n",
        "- **Speech-to-Text Conversion**: Powered by Whisper, enabling you to submit requests via voice commands.\n",
        "- **Entity Extraction**: Utilizing a fine-tuned spaCy model to identify key details such as project name, amount, and reason from your input.\n",
        "- **Database Integration**: Effortlessly store and retrieve your requests with the built-in database functionality.\n",
        "\n",
        "### Key Features:\n",
        "1. **Text and Voice Input**: Submit your funding requests through text or voice commands for maximum convenience.\n",
        "2. **Entity Recognition**: Automatically extract and validate essential information like project name, amount, and reason.\n",
        "3. **Database Records**: View all your previously submitted requests in an easy-to-read format.\n",
        "4. **User-Friendly Interface**: A clean and intuitive design to make your experience seamless.\n",
        "\n",
        "This application simplifies the process of managing project funding requests, ensuring accuracy, efficiency, and a user-friendly interaction. Start exploring today!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClokzGMHQKqn"
      },
      "source": [
        "# Tools and Requirements\n",
        "\n",
        "### Tools Used\n",
        "1. **[Whisper](https://github.com/openai/whisper)**  \n",
        "   - **Purpose**: Converts voice input to text for speech-to-text functionality.  \n",
        "   - **Reason**: Whisper's state-of-the-art accuracy and multilingual support make it ideal for processing natural speech inputs.  \n",
        "   - **Open Source**: Yes, enabling customization and integration.\n",
        "\n",
        "2. **[spaCy](https://spacy.io/)**  \n",
        "   - **Purpose**: Extracts key entities like project name, amount, and reason from the input text.  \n",
        "   - **Reason**: spaCy is highly efficient for Named Entity Recognition (NER) tasks and supports fine-tuning for domain-specific needs.  \n",
        "   - **Open Source**: Yes, allowing fine-tuning and deployment without licensing concerns.\n",
        "\n",
        "3. **[Gradio](https://gradio.app/)**  \n",
        "   - **Purpose**: Provides a user-friendly interface for text and voice input.  \n",
        "   - **Reason**: Gradio simplifies the creation of interactive AI applications with minimal code.  \n",
        "   - **Open Source**: Yes, enabling seamless integration into any Python project.\n",
        "\n",
        "4. **SQLite**  \n",
        "   - **Purpose**: Stores project funding requests in a lightweight, easily accessible database.  \n",
        "   - **Reason**: SQLite is simple, file-based, and requires no additional setup, making it perfect for prototyping.  \n",
        "   - **Open Source**: Yes, with no licensing costs.\n",
        "\n",
        "---\n",
        "\n",
        "### Why These Tools Were Chosen\n",
        "The combination of Whisper, spaCy, Gradio, and SQLite ensures that the app is:  \n",
        "- **Accurate**: Whisper and spaCy provide reliable speech recognition and entity extraction.  \n",
        "- **User-Friendly**: Gradio offers a clean, intuitive interface for end-users.  \n",
        "- **Efficient**: SQLite handles data storage without additional infrastructure requirements.  \n",
        "- **Customizable**: Open-source tools allow for modifications, extensions, and domain-specific enhancements.\n",
        "\n",
        "---\n",
        "\n",
        "### Future Improvements\n",
        "1. **Arabic Language Support**:  \n",
        "   - Extend the model fine-tuning to handle Arabic inputs for both speech-to-text and entity extraction.  \n",
        "   - This would enhance accessibility for Arabic-speaking users.  \n",
        "   - Example: Fine-tune Whisper's multilingual support and spaCy's NER for Arabic-specific patterns.\n",
        "\n",
        "2. **Enhanced Validation**:  \n",
        "   - Improve validation for inputs by incorporating more robust checks for field consistency (e.g., currency formats and project name validation).  \n",
        "\n",
        "3. **Advanced Database Features**:  \n",
        "   - Add features like filtering, sorting, and exporting requests for better data management.  \n",
        "\n",
        "4. **Interactive Insights**:  \n",
        "   - Visualize stored data using graphs or dashboards to track project funding trends over time.\n",
        "\n",
        "5. **Model Fine-Tuning**:  \n",
        "   - Continue fine-tuning the spaCy model with a larger dataset of domain-specific examples for improved accuracy.\n",
        "\n",
        "6. **Voice Accuracy Enhancement**:  \n",
        "   - Integrate custom training for Whisper to improve transcription accuracy for noisy environments and accents.\n",
        "\n",
        "---\n",
        "\n",
        "### Open Source Benefits\n",
        "Using open-source tools not only reduces costs but also provides the flexibility to customize the application. Contributions from the community can further enhance the functionality and user experience. Open-source principles also align with the goal of making AI accessible and transparent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odXGXVVMTWNo"
      },
      "source": [
        "\n",
        "\n",
        "#Implementation..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esac-gSTSnMf"
      },
      "source": [
        "\n",
        "# Step-1 Dataset creation for example problem\n",
        "---------------------------------------------\n",
        "\n",
        "### 1. Creating a Dataset\n",
        "To address the problem of extracting key entities like project names, reasons, and amounts from textual requests, the first step is generating a dataset with labeled examples.  \n",
        "\n",
        "#### Dataset Generation\n",
        "- **Process**: We used Python's `random` library to generate 1000 synthetic sentences simulating real-world money request scenarios.  \n",
        "- **Entities Labeled**: Each sentence includes three key entities:  \n",
        "  - **PROJECT**: Represents the project name.  \n",
        "  - **MONEY**: Indicates the amount being requested.  \n",
        "  - **REASON**: Explains the purpose of the request.  \n",
        "- **Sentence Variations**: Multiple sentence structures were created to improve model robustness and handle diverse inputs.\n",
        "\n",
        "#### Example Sentences in the Dataset\n",
        "```python\n",
        "[\n",
        "    (\n",
        "        \"I need to request money for project 223 to buy some tools. The amount I need is 500 Riyals.\",\n",
        "        {\"entities\": [(30, 33, \"PROJECT\"), (67, 71, \"REASON\"), (91, 101, \"MONEY\")]}\n",
        "    ),\n",
        "    (\n",
        "        \"Requesting 3000 Riyals for project AI Innovation Lab to fund research.\",\n",
        "        {\"entities\": [(35, 51, \"PROJECT\"), (58, 71, \"REASON\"), (11, 22, \"MONEY\")]}\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqBAly9O-avn",
        "outputId": "14c3b432-264a-4db4-fba8-696f44213bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('I want to request 1000 Riyals for procure equipment for project 223.', {'entities': [(64, 67, 'PROJECT'), (18, 29, 'MONEY'), (34, 51, 'REASON')]})\n",
            "('Please allocate 1000 Riyals for the project Abha University because I need to procure equipment.', {'entities': [(44, 59, 'PROJECT'), (16, 27, 'MONEY'), (78, 95, 'REASON')]})\n",
            "('I need to request money for project Green Energy Project to purchase hardware. The amount I need is 500 Riyals.', {'entities': [(36, 56, 'PROJECT'), (100, 110, 'MONEY'), (60, 77, 'REASON')]})\n",
            "('Please allocate 3000 Riyals for the project Abha University because I need to buy some tools.', {'entities': [(44, 59, 'PROJECT'), (16, 27, 'MONEY'), (78, 92, 'REASON')]})\n",
            "('Requesting 3000 Riyals for project AI Innovation Lab to fund research.', {'entities': [(35, 52, 'PROJECT'), (11, 22, 'MONEY'), (56, 69, 'REASON')]})\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "projects = [\"223\", \"Abha University\", \"AI Innovation Lab\", \"Green Energy Project\"]\n",
        "reasons = [\"buy some tools\", \"purchase hardware\", \"procure equipment\", \"fund research\"]\n",
        "amounts = [\"500 Riyals\", \"1000 Riyals\", \"2000 Riyals\", \"3000 Riyals\"]\n",
        "\n",
        "training_data = []\n",
        "\n",
        "for _ in range(1000):  # Generate 1000 samples\n",
        "    project = random.choice(projects)\n",
        "    reason = random.choice(reasons)\n",
        "    amount = random.choice(amounts)\n",
        "\n",
        "    sentence_variations = [\n",
        "        f\"I need to request money for project {project} to {reason}. The amount I need is {amount}.\",\n",
        "        f\"I want to request {amount} for {reason} for project {project}.\",\n",
        "        f\"Please allocate {amount} for the project {project} because I need to {reason}.\",\n",
        "        f\"Requesting {amount} for project {project} to {reason}.\",\n",
        "    ]\n",
        "\n",
        "    sentence = random.choice(sentence_variations)\n",
        "    entities = {\n",
        "        \"entities\": [\n",
        "            (sentence.index(project), sentence.index(project) + len(project), \"PROJECT\"),\n",
        "            (sentence.index(amount), sentence.index(amount) + len(amount), \"MONEY\"),\n",
        "            (sentence.index(reason), sentence.index(reason) + len(reason), \"REASON\"),\n",
        "        ]\n",
        "    }\n",
        "    training_data.append((sentence, entities))\n",
        "\n",
        "# Print a few samples of the training data\n",
        "for data in training_data[:5]:\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMy40LSG_axS",
        "outputId": "f2435537-7698-482c-836c-2898dd4944e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "#downloading the pretrained en_core_web_md spacy model. Also there are other models sm, lg available\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EzwpJnBV0vK"
      },
      "source": [
        "# Step-2 Fine-tune the spaCy Model for Named Entity Recognition (NER) on our custom dataset\n",
        "\n",
        "### Overview\n",
        "This section describes the process of fine-tuning a spaCy model to recognize domain-specific entities, such as project names, monetary amounts, and reasons, from text data.  \n",
        "\n",
        "---\n",
        "\n",
        "### Steps for Training\n",
        "\n",
        "1. **Model Setup**:\n",
        "   - We used the **pre-trained `en_core_web_md` spaCy model** for its rich linguistic features and vocabulary.\n",
        "\n",
        "2. **Adding the Named Entity Recognizer (NER)**:\n",
        "   - Checked if the NER pipeline existed in the model; if not, it was added.\n",
        "   - Labels (e.g., \"PROJECT\", \"MONEY\", \"REASON\") were introduced to the NER component based on the dataset.\n",
        "\n",
        "3. **Optimizing Hyperparameters**:\n",
        "   - **Number of Iterations**: Set to **50** for effective learning.\n",
        "   - **Batch Size**: Used a batch size of **16** to balance training speed and model accuracy.\n",
        "   - **Learning Rate**: Adjusted to **0.001** for precise gradient updates during fine-tuning.\n",
        "\n",
        "4. **Training Process**:\n",
        "   - All pipelines except NER were disabled for focused training.\n",
        "   - A minibatch approach was employed to train the model on small, randomized subsets of data for efficiency.\n",
        "   - For each example, the text was converted into a spaCy `Example` object, and the model was updated iteratively to minimize the loss.\n",
        "\n",
        "5. **Saving the Fine-Tuned Model**:\n",
        "   - After training, the fine-tuned model was saved locally for later use in inference tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### Outcome\n",
        "This process successfully produced a fine-tuned spaCy NER model capable of identifying PROJECT, MONEY, and REASON entities from text data with high precision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaPLaDHy_DUo",
        "outputId": "dd22afe8-27be-4008-a364-a0c9794b5bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1 - Losses: {'ner': 314.63099747429385}\n",
            "Iteration 2 - Losses: {'ner': 2.200482643013824e-05}\n",
            "Iteration 3 - Losses: {'ner': 1.4298861095634986e-05}\n",
            "Iteration 4 - Losses: {'ner': 21.773064165830647}\n",
            "Iteration 5 - Losses: {'ner': 15.397861972348933}\n",
            "Iteration 6 - Losses: {'ner': 0.11569479066907401}\n",
            "Iteration 7 - Losses: {'ner': 23.77775287350021}\n",
            "Iteration 8 - Losses: {'ner': 8.503669715910798e-06}\n",
            "Iteration 9 - Losses: {'ner': 7.270270054002184e-07}\n",
            "Iteration 10 - Losses: {'ner': 3.300903324582586e-06}\n",
            "Iteration 11 - Losses: {'ner': 1.450074863159155e-07}\n",
            "Iteration 12 - Losses: {'ner': 8.019611526038751e-09}\n",
            "Iteration 13 - Losses: {'ner': 48.54660216803205}\n",
            "Iteration 14 - Losses: {'ner': 2.5569016112909982e-06}\n",
            "Iteration 15 - Losses: {'ner': 6.826244408006239e-09}\n",
            "Iteration 16 - Losses: {'ner': 2.3935390260848404e-09}\n",
            "Iteration 17 - Losses: {'ner': 1.7867097278623228e-08}\n",
            "Iteration 18 - Losses: {'ner': 1.0699680056603255e-08}\n",
            "Iteration 19 - Losses: {'ner': 2.042795473277904e-05}\n",
            "Iteration 20 - Losses: {'ner': 26.95906402420884}\n",
            "Iteration 21 - Losses: {'ner': 8.084349078375239e-09}\n",
            "Iteration 22 - Losses: {'ner': 0.013216674674788619}\n",
            "Iteration 23 - Losses: {'ner': 18.465107568014822}\n",
            "Iteration 24 - Losses: {'ner': 4.6072662760584574e-09}\n",
            "Iteration 25 - Losses: {'ner': 4.031283561705445e-09}\n",
            "Iteration 26 - Losses: {'ner': 3.156933867128423e-07}\n",
            "Iteration 27 - Losses: {'ner': 1.4391769725244548e-10}\n",
            "Iteration 28 - Losses: {'ner': 29.170038093711735}\n",
            "Iteration 29 - Losses: {'ner': 1.921958400216304e-05}\n",
            "Iteration 30 - Losses: {'ner': 3.472855886895736e-08}\n",
            "Iteration 31 - Losses: {'ner': 31.818525917816586}\n",
            "Iteration 32 - Losses: {'ner': 8.006497236719234}\n",
            "Iteration 33 - Losses: {'ner': 3.5653792760281305e-12}\n",
            "Iteration 34 - Losses: {'ner': 1.706946841453098e-11}\n",
            "Iteration 35 - Losses: {'ner': 7.329398435314295e-07}\n",
            "Iteration 36 - Losses: {'ner': 2.9269619129020506e-10}\n",
            "Iteration 37 - Losses: {'ner': 1.7481036714084887e-08}\n",
            "Iteration 38 - Losses: {'ner': 7.054135242155265e-13}\n",
            "Iteration 39 - Losses: {'ner': 1.759815868894282e-11}\n",
            "Iteration 40 - Losses: {'ner': 2.1155906782288797e-08}\n",
            "Iteration 41 - Losses: {'ner': 2.4247620737487827e-09}\n",
            "Iteration 42 - Losses: {'ner': 7.359887967672732e-11}\n",
            "Iteration 43 - Losses: {'ner': 2.6496753088769172e-12}\n",
            "Iteration 44 - Losses: {'ner': 4.5063119138797145e-12}\n",
            "Iteration 45 - Losses: {'ner': 2.7703374478861843e-13}\n",
            "Iteration 46 - Losses: {'ner': 2.3872903256426723e-12}\n",
            "Iteration 47 - Losses: {'ner': 2.0500267041541223e-11}\n",
            "Iteration 48 - Losses: {'ner': 1.8068848814526335e-14}\n",
            "Iteration 49 - Losses: {'ner': 5.6327855569494123e-14}\n",
            "Iteration 50 - Losses: {'ner': 9.221022914907272e-14}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import random\n",
        "from spacy.util import minibatch\n",
        "\n",
        "# Load the pre-trained model or create a blank English model\n",
        "nlp = spacy.load(\"en_core_web_md\")  # or spacy.blank(\"en\") for a blank model\n",
        "\n",
        "\n",
        "TRAINING_DATA = training_data\n",
        "\n",
        "# Get the Named Entity Recognizer (NER) pipeline\n",
        "if \"ner\" not in nlp.pipe_names:\n",
        "    ner = nlp.add_pipe(\"ner\", last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add labels to the NER\n",
        "for _, annotations in TRAINING_DATA:\n",
        "    for ent in annotations[\"entities\"]:\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "# Disable other pipelines during training\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "# Optimize hyperparameters\n",
        "n_iterations = 50  # Increase the number of iterations\n",
        "batch_size = 16  # Use larger batch size for better learning\n",
        "learning_rate = 0.001  # Lower learning rate for fine-tuning\n",
        "\n",
        "def create_batches(data, size):\n",
        "    return minibatch(data, size=size)\n",
        "\n",
        "# Train the model\n",
        "with nlp.disable_pipes(*unaffected_pipes):  # Only train NER\n",
        "    optimizer = nlp.create_optimizer()\n",
        "    for itn in range(n_iterations):  # Number of iterations\n",
        "        random.shuffle(TRAINING_DATA)\n",
        "        losses = {}\n",
        "        batches = create_batches(TRAINING_DATA, size=batch_size)\n",
        "        for batch in batches:\n",
        "            for text, annotations in batch:\n",
        "                doc = nlp.make_doc(text)\n",
        "                example = Example.from_dict(doc, annotations)\n",
        "                nlp.update([example], drop=0.2, losses=losses, sgd=optimizer)\n",
        "        print(f\"Iteration {itn + 1} - Losses: {losses}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "nlp.to_disk(r\"fine_tuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k-irRfOdHV-T",
        "outputId": "c622ed14-ccdd-4af7-f61b-5a23544e748d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.9.0)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803320 sha256=1ace571f163833d957296c2e01b8ec950a3f52fd5a08866808e3c55562d62fcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "847bdcad3f534882bf533bf947b84a62",
              "pip_warning": {
                "packages": [
                  "whisper"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install necessary libraries:\n",
        "# - gradio: For creating user-friendly web interfaces for the application.\n",
        "# - openai-whisper: For leveraging OpenAI's Whisper model for speech-to-text functionality.\n",
        "\n",
        "pip install gradio openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewVxzhDLX1dt"
      },
      "source": [
        "# Step-3 Integration of Speech-to-Text, Entity Extraction, and Database Interaction in Gradio App\n",
        "\n",
        "This Gradio app integrates various functionalities to process money requests for projects through both text and voice inputs. The app performs speech-to-text conversion, entity extraction, and interacts with an SQLite database to store and retrieve money request data.\n",
        "\n",
        "### Key Steps:\n",
        "1. **Speech-to-Text Integration**:\n",
        "   - The Whisper model is used to convert audio input into text for further processing.\n",
        "   - If the user provides audio, it is transcribed into text before extracting entities.\n",
        "\n",
        "2. **Entity Extraction**:\n",
        "   - Using spaCy's fine-tuned model, the app extracts key entities like `project_name`, `amount`, and `reason` from the text input. These entities are essential for processing the money request.\n",
        "\n",
        "3. **Database Integration**:\n",
        "   - The app interacts with an SQLite database (`erp.db`) to store money requests with the extracted data (project name, amount, reason).\n",
        "   - A table (`money_requests`) is created to store requests if it doesn't already exist.\n",
        "   - Users can view the stored requests by querying the database.\n",
        "\n",
        "### Gradio Interface:\n",
        "- **Submit Request**: Users can submit money requests either by typing text or using audio input.\n",
        "- **View Records**: Users can view existing records from the database through a simple interface.\n",
        "\n",
        "### Functions:\n",
        "- `speech_to_text(audio)`: Converts audio input to text.\n",
        "- `extract_entities(text)`: Extracts key entities from the text input.\n",
        "- `add_request_to_db(project_name, amount, reason)`: Stores the money request in the SQLite database.\n",
        "- `view_database_records()`: Retrieves and displays all stored money requests.\n",
        "- `process_request(text_input)`: Processes the request, extracts entities, and interacts with the database.\n",
        "\n",
        "The app is built using Gradio, providing an interactive user interface for both submitting requests and viewing records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "eC2o9K9_Dxhb",
        "outputId": "93170b69-76c3-438d-aeef-90668621cbe2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fddda44c6479e00171.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fddda44c6479e00171.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import whisper\n",
        "import spacy\n",
        "import sqlite3\n",
        "\n",
        "# Load Whisper model for speech-to-text\n",
        "stt_model = whisper.load_model(\"base\")\n",
        "\n",
        "# Load spaCy for entity extraction\n",
        "nlp = spacy.load(\"fine_tuned_model\")\n",
        "\n",
        "# Global variables to store request data\n",
        "project_name = \"\"\n",
        "amount = \"\"\n",
        "reason = \"\"\n",
        "\n",
        "\n",
        "# Speech-to-text function\n",
        "def speech_to_text(audio):\n",
        "    result = stt_model.transcribe(audio.name)\n",
        "    print(result[\"text\"])\n",
        "    return result[\"text\"]\n",
        "\n",
        "\n",
        "# Extract entities using spaCy\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        entities[ent.label_] = ent.text\n",
        "    return entities\n",
        "\n",
        "\n",
        "# Add request to database\n",
        "def add_request_to_db(project_name, amount, reason):\n",
        "    conn = sqlite3.connect(\"erp.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"CREATE TABLE IF NOT EXISTS money_requests (project_name TEXT, amount REAL, reason TEXT)\")\n",
        "    cursor.execute(\"INSERT INTO money_requests (project_name, amount, reason) VALUES (?, ?, ?)\",\n",
        "                   (project_name, amount, reason))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "# Retrieve records from the database\n",
        "def view_database_records():\n",
        "    conn = sqlite3.connect(\"erp.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"CREATE TABLE IF NOT EXISTS money_requests (project_name TEXT, amount REAL, reason TEXT)\")\n",
        "    records = cursor.execute(\"SELECT * FROM money_requests\").fetchall()\n",
        "    conn.close()\n",
        "    if not records:\n",
        "        return \"No records found.\"\n",
        "    return records\n",
        "\n",
        "\n",
        "# Process text/audio requests\n",
        "def process_request(text_input):\n",
        "    global project_name, amount, reason\n",
        "    \n",
        "    if not project_name or not amount or not reason:\n",
        "        # If required data isn't available, extract entities\n",
        "        entities = extract_entities(text_input)\n",
        "        project_name = entities.get('PROJECT', '')\n",
        "        amount = entities.get('MONEY', '')\n",
        "        reason = entities.get('REASON', '')\n",
        "\n",
        "        if not project_name or not amount or not reason:\n",
        "            missing_fields = []\n",
        "            if not project_name:\n",
        "                missing_fields.append(\"project name\")\n",
        "            if not amount:\n",
        "                missing_fields.append(\"amount\")\n",
        "            if not reason:\n",
        "                missing_fields.append(\"reason\")\n",
        "            return f\"Missing fields: {', '.join(missing_fields)}. Please provide the missing information.\"\n",
        "\n",
        "        return f\"You are going to add a request for project: {project_name}, request amount: {amount}, reason: {reason}. Are you sure you want to proceed? Yes/No\"\n",
        "    \n",
        "    # Confirmation Step\n",
        "    if \"yes\" in text_input.lower() or \"okay\" in text_input.lower() or \"confirm\" in text_input.lower():\n",
        "        add_request_to_db(project_name, amount, reason)\n",
        "        project_name_temp=project_name\n",
        "        amount_temp=amount\n",
        "        reason_temp=reason\n",
        "        project_name, amount, reason = \"\", \"\", \"\"  # Reset the global variables after the request is added\n",
        "        return f\"Your request for project '{project_name_temp}' with amount {amount_temp} for {reason_temp} has been submitted successfully.\"\n",
        "        \n",
        "    else:\n",
        "        project_name, amount, reason = \"\", \"\", \"\"  # Reset the global variables if canceled\n",
        "        return \"Request has been canceled.\"\n",
        "\n",
        "\n",
        "# Gradio Interface for handling chatbot and database interactions\n",
        "def chatbot_interface(text_input, audio_input=None):\n",
        "    if audio_input:\n",
        "        text_input = speech_to_text(audio_input)\n",
        "    \n",
        "    # Process the request and confirmation flow\n",
        "    return process_request(text_input)\n",
        "\n",
        "\n",
        "# Gradio Interface for viewing database records\n",
        "def database_view_interface():\n",
        "    return view_database_records()\n",
        "\n",
        "\n",
        "# Create the Gradio Interface\n",
        "iface = gr.Blocks()\n",
        "\n",
        "with iface:\n",
        "    gr.Markdown(\"# AI Agent for Money Requests\")\n",
        "    gr.Markdown(\"Use text or voice commands to request money for a project or view existing records.\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### Submit Request\")\n",
        "            text_input = gr.Textbox(label=\"Enter your text request:\", placeholder=\"Type your message here...\")\n",
        "            audio_input = gr.Audio(label=\"Or use voice input:\", sources=\"microphone\")\n",
        "            submit_button = gr.Button(\"Submit Request\")\n",
        "            \n",
        "        \n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### AI Agent Response\")\n",
        "            response_output = gr.Textbox(label=\"Response:\")\n",
        "            gr.Markdown(\"### View Database Records\")\n",
        "            view_records_button = gr.Button(\"View Records\")\n",
        "            records_output = gr.Textbox(label=\"Database Records:\")\n",
        "\n",
        "    # Bind functions\n",
        "    submit_button.click(fn=chatbot_interface, inputs=[text_input, audio_input], outputs=response_output)\n",
        "    view_records_button.click(fn=database_view_interface, outputs=records_output)\n",
        "\n",
        "# Launch the Interface\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
